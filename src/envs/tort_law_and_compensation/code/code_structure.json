{
  "agents": {
    "Plaintiff": {
      "imports": "from typing import Any, List,Optional\nimport json\nimport asyncio\nfrom loguru import logger\nfrom onesim.models import JsonBlockParser\nfrom onesim.agent import GeneralAgent\nfrom onesim.profile import AgentProfile\nfrom onesim.memory import MemoryStrategy\nfrom onesim.planning import PlanningBase\nfrom onesim.events import *\nfrom onesim.relationship import RelationshipManager\nfrom .events import *",
      "handlers": {
        "1": {
          "code": "async def submit_compensation_request(self, event: Event) -> List[Event]:\n        # Condition Check\n        if event.__class__.__name__ != \"StartEvent\":\n            return []\n        \n        # Data Access\n        compensation_amount = self.profile.get_data(\"compensation_amount\", 0.0)\n        damage_description = self.profile.get_data(\"damage_description\", \"\")\n        evidence_list = self.profile.get_data(\"evidence_list\", [])\n        \n        # Decision Making\n        instruction = \"\"\"Context: The Plaintiff is submitting a compensation request in a tort law case. \n        The request includes the compensation amount, damage description, and supporting evidence. \n        The Plaintiff needs to determine the target Judge(s) for evaluating the request.\n        Please return the information in the following JSON format:\n        {\n        \"compensation_amount\": \"<Requested amount for compensation>\",\n        \"damage_description\": \"<Description of the damages incurred>\",\n        \"evidence_list\": <List of evidence supporting the compensation request>,\n        \"target_ids\": [\"<The string ID(s) of the Judge agent(s)>\"]\n        }\n        \"\"\"\n        \n        observation = f\"Compensation Amount: {compensation_amount}, Damage Description: {damage_description}, Evidence List: {evidence_list}\"\n        result = await self.generate_reaction(instruction, observation)\n        \n        # Response Processing\n        compensation_amount = result.get('compensation_amount', compensation_amount)\n        damage_description = result.get('damage_description', damage_description)\n        evidence_list = result.get('evidence_list', evidence_list)\n        target_ids = result.get('target_ids', [])\n        if not isinstance(target_ids, list):\n            target_ids = [target_ids]\n        \n        # Prepare and send the CompensationRequestEvent to the Judge(s)\n        events = []\n        for target_id in target_ids:\n            compensation_event = CompensationRequestEvent(self.profile_id, target_id, compensation_amount, damage_description, evidence_list)\n            events.append(compensation_event)\n        \n        # Update agent profile\n        self.profile.update_data(\"compensation_request_submitted\", True)\n        \n        return events",
          "metadata": {
            "id": 1,
            "name": "submit_compensation_request",
            "condition": "null",
            "description": "The Plaintiff submits a compensation request detailing the damages incurred and supporting evidence.",
            "type": "OR",
            "required_variables": [
              {
                "name": "compensation_amount",
                "type": "float",
                "context": "agent",
                "description": "Requested amount for compensation"
              },
              {
                "name": "damage_description",
                "type": "str",
                "context": "agent",
                "description": "Description of the damages incurred"
              },
              {
                "name": "evidence_list",
                "type": "list",
                "context": "agent",
                "description": "List of evidence supporting the compensation request"
              }
            ],
            "output_updates": [
              {
                "name": "compensation_request_submitted",
                "type": "bool",
                "context": "agent",
                "description": "Status indicating that the compensation request has been submitted"
              }
            ]
          }
        }
      }
    },
    "Defendant": {
      "imports": "from typing import Any, List,Optional\nimport json\nimport asyncio\nfrom loguru import logger\nfrom onesim.models import JsonBlockParser\nfrom onesim.agent import GeneralAgent\nfrom onesim.profile import AgentProfile\nfrom onesim.memory import MemoryStrategy\nfrom onesim.planning import PlanningBase\nfrom onesim.events import *\nfrom onesim.relationship import RelationshipManager\nfrom .events import *",
      "handlers": {
        "2": {
          "code": "async def prepare_defense(self, event: Event) -> List[Event]:\n        # Condition check for 'null' condition\n        if event.__class__.__name__ != \"StartEvent\":\n            return []\n    \n        # Access required variables from agent context\n        liability_reduction_argument = self.profile.get_data(\"liability_reduction_argument\", \"\")\n        counter_evidence_list = self.profile.get_data(\"counter_evidence_list\", [])\n    \n        # Instruction for generating defense preparation reaction\n        instruction = \"\"\"Please prepare the defense argument for liability reduction, including counter-evidence.\n        Return the information in the following JSON format:\n    \n        {\n        \"liability_reduction_argument\": \"<Argument prepared by the defendant for reducing liability>\",\n        \"counter_evidence_list\": <List of evidence countering the plaintiff's claims>,\n        \"target_ids\": \"<The string ID of the Judge agent>\"\n        }\n        \"\"\"\n    \n        # Generate the reaction using the LLM\n        result = await self.generate_reaction(instruction)\n    \n        # Process the LLM's response\n        liability_reduction_argument = result.get('liability_reduction_argument', liability_reduction_argument)\n        counter_evidence_list = result.get('counter_evidence_list', counter_evidence_list)\n        target_ids = result.get('target_ids', None)\n        if not isinstance(target_ids, list):\n            target_ids = [target_ids]\n    \n        # Update agent's state indicating defense has been prepared\n        self.profile.update_data(\"defense_prepared\", True)\n    \n        # Prepare and send DefensePreparedEvent to the Judge\n        events = []\n        for target_id in target_ids:\n            defense_event = DefensePreparedEvent(\n                self.profile_id, target_id,\n                liability_reduction_argument=liability_reduction_argument,\n                counter_evidence_list=counter_evidence_list\n            )\n            events.append(defense_event)\n    \n        return events",
          "metadata": {
            "id": 2,
            "name": "prepare_defense",
            "condition": "null",
            "description": "The Defendant prepares a defense to argue for liability reduction, including counter-evidence.",
            "type": "OR",
            "required_variables": [
              {
                "name": "liability_reduction_argument",
                "type": "str",
                "context": "agent",
                "description": "Argument prepared by the defendant for reducing liability"
              },
              {
                "name": "counter_evidence_list",
                "type": "list",
                "context": "agent",
                "description": "List of evidence countering the plaintiff's claims"
              }
            ],
            "output_updates": [
              {
                "name": "defense_prepared",
                "type": "bool",
                "context": "agent",
                "description": "Status indicating that the defense has been prepared"
              }
            ]
          }
        }
      }
    },
    "Judge": {
      "imports": "from typing import Any, List, Optional\nimport json\nimport asyncio\nfrom loguru import logger\nfrom onesim.models import JsonBlockParser\nfrom onesim.agent import GeneralAgent\nfrom onesim.profile import AgentProfile\nfrom onesim.memory import MemoryStrategy\nfrom onesim.planning import PlanningBase\nfrom onesim.events import *\nfrom onesim.relationship import RelationshipManager\nfrom .events import *",
      "handlers": {
        "3": {
          "code": "async def evaluate_request(self, event: Event) -> List[Event]:\n        # Mark event as received\n        received_events = self.profile.get_data('received_events', [])\n        if \"CompensationRequestEvent\" not in received_events:\n            received_events.append(\"CompensationRequestEvent\")\n        self.profile.update_data('received_events', received_events)\n\n        # Check if both CompensationRequestEvent and DefensePreparedEvent have been received\n        if \"DefensePreparedEvent\" not in received_events:\n            return []  # Return an empty list if the condition is not met\n\n        # Retrieve event data\n        compensation_amount = event.compensation_amount\n        damage_description = event.damage_description\n        evidence_list = event.evidence_list\n\n        # Construct observation and instruction for decision making\n        observation = f\"Compensation Amount: {compensation_amount}, Damage Description: {damage_description}, Evidence List: {evidence_list}\"\n        instruction = \"\"\"Evaluate the compensation request based on the provided evidence and damage description. \n        Consider legal principles and precedents to determine the evaluation status and notes.\n        Return the information in the following JSON format:\n\n        {\n        \"evaluation_status\": \"<Status of the evaluation process>\",\n        \"evaluation_notes\": \"<Notes and observations made during the evaluation>\",\n        \"target_ids\": [\"<The string ID of the Judge agent for the next action>\"]\n        }\n        \"\"\"\n\n        # Generate reaction using LLM\n        result = await self.generate_reaction(instruction, observation)\n\n        # Extract evaluation results and target_ids\n        evaluation_status = result.get('evaluation_status', None)\n        evaluation_notes = result.get('evaluation_notes', None)\n        target_ids = result.get('target_ids', None)\n        if not isinstance(target_ids, list):\n            target_ids = [target_ids]\n\n        # Update agent's state with evaluation results\n        self.profile.update_data(\"evaluation_status_request\", \"completed\")\n        self.profile.update_data(\"evaluation_notes_request\", evaluation_notes)\n\n        # Prepare and send RequestEvaluationEvent to specified targets\n        events = []\n        for target_id in target_ids:\n            evaluation_event = RequestEvaluationEvent(self.profile_id, target_id, evaluation_status, evaluation_notes)\n            events.append(evaluation_event)\n\n        return events",
          "metadata": {
            "id": 3,
            "name": "evaluate_request",
            "condition": "CompensationRequestEvent and DefensePreparedEvent received",
            "description": "The Judge evaluates the compensation request submitted by the Plaintiff, considering the evidence provided.",
            "type": "OR",
            "required_variables": [
              {
                "name": "compensation_amount",
                "type": "float",
                "context": "event",
                "description": "Requested amount for compensation"
              },
              {
                "name": "damage_description",
                "type": "str",
                "context": "event",
                "description": "Description of the damages incurred"
              },
              {
                "name": "evidence_list",
                "type": "list",
                "context": "event",
                "description": "List of evidence supporting the compensation request"
              }
            ],
            "output_updates": [
              {
                "name": "evaluation_status",
                "type": "str",
                "context": "agent",
                "description": "Status of the evaluation process"
              },
              {
                "name": "evaluation_notes",
                "type": "str",
                "context": "agent",
                "description": "Notes and observations made during the evaluation"
              }
            ]
          }
        },
        "4": {
          "code": "async def evaluate_defense(self, event: Event) -> List[Event]:\n        # Mark event as received\n        received_events = self.profile.get_data('received_events', [])\n        if \"DefensePreparedEvent\" not in received_events:\n            received_events.append(\"DefensePreparedEvent\")\n        self.profile.update_data('received_events', received_events)\n\n        # Check if both CompensationRequestEvent and DefensePreparedEvent have been received\n        if \"CompensationRequestEvent\" not in received_events:\n            return []\n\n        # Retrieve required variables from the event\n        liability_reduction_argument = getattr(event, \"liability_reduction_argument\", \"\")\n        counter_evidence_list = getattr(event, \"counter_evidence_list\", [])\n\n        # Prepare the observation for the LLM\n        observation = (\n            f\"Liability Reduction Argument: {liability_reduction_argument}\\n\"\n            f\"Counter Evidence List: {counter_evidence_list}\"\n        )\n\n        # Instruction for generating a reaction to the event\n        instruction = \"\"\"Evaluate the defense arguments using the provided liability_reduction_argument and counter_evidence_list.\n        Based on the evaluation, return the evaluation_status and evaluation_notes.\n        Also, specify the target_ids for the next action, which can be a single ID or a list of IDs.\n        Please return the information in the following JSON format:\n        \n        {\n        \"evaluation_status\": \"<Status of the defense evaluation process>\",\n        \"evaluation_notes\": \"<Notes and observations made during the defense evaluation>\",\n        \"target_ids\": [\"<The ID(s) for the next action>\"]\n        }\n        \"\"\"\n\n        # Generate a reaction using the LLM\n        result = await self.generate_reaction(instruction, observation)\n\n        # Update agent profile with evaluation results\n        evaluation_status = result.get(\"evaluation_status\", \"completed\")\n        evaluation_notes = result.get(\"evaluation_notes\", \"\")\n        self.profile.update_data(\"evaluation_status_defense\", \"completed\")\n        self.profile.update_data(\"evaluation_notes_defense\", evaluation_notes)\n\n        # Determine target_ids and ensure it's a list\n        target_ids = result.get(\"target_ids\", [])\n        if not isinstance(target_ids, list):\n            target_ids = [target_ids]\n\n        # Prepare and send DefenseEvaluationEvent to the specified target(s)\n        events = []\n        for target_id in target_ids:\n            defense_evaluation_event = DefenseEvaluationEvent(self.profile_id, target_id, evaluation_status, evaluation_notes)\n            events.append(defense_evaluation_event)\n\n        return events",
          "metadata": {
            "id": 4,
            "name": "evaluate_defense",
            "condition": "CompensationRequestEvent and DefensePreparedEvent received",
            "description": "The Judge evaluates the defense arguments presented by the Defendant, assessing the counter-evidence provided.",
            "type": "OR",
            "required_variables": [
              {
                "name": "liability_reduction_argument",
                "type": "str",
                "context": "event",
                "description": "Argument prepared by the defendant for reducing liability"
              },
              {
                "name": "counter_evidence_list",
                "type": "list",
                "context": "event",
                "description": "List of evidence countering the plaintiff's claims"
              }
            ],
            "output_updates": [
              {
                "name": "evaluation_status",
                "type": "str",
                "context": "agent",
                "description": "Status of the defense evaluation process"
              },
              {
                "name": "evaluation_notes",
                "type": "str",
                "context": "agent",
                "description": "Notes and observations made during the defense evaluation"
              }
            ]
          }
        },
        "5": {
          "code": "async def make_decision(self, event: Event) -> List[Event]:\n        # Retrieve evaluation statuses from agent profile\n        evaluation_status_request = self.profile.get_data(\"evaluation_status_request\", \"pending\")\n        evaluation_status_defense = self.profile.get_data(\"evaluation_status_defense\", \"pending\")\n\n        # Ensure both evaluation statuses are marked as 'completed'\n        if evaluation_status_request != \"completed\" or evaluation_status_defense != \"completed\":\n            return []\n\n        # Prepare observation and instruction for decision making\n        observation = f\"Evaluation status request: {evaluation_status_request}, Evaluation status defense: {evaluation_status_defense}\"\n        instruction = \"\"\"Please make a decision based on the completed evaluations of both the compensation request and the defense arguments.\n        Return the outcome of the decision, amount of compensation awarded, and completion status in the following JSON format:\n\n        {\n        \"decision_outcome\": \"<Outcome of the case decision>\",\n        \"compensation_awarded\": <Amount of compensation awarded to the plaintiff>,\n        \"completion_status\": \"<Status indicating completion of the case>\",\n        \"target_ids\": [\"<The string ID of the EnvAgent>\"]\n        }\n        \"\"\"\n\n        # Generate reaction using the LLM\n        result = await self.generate_reaction(instruction, observation)\n\n        # Parse the LLM's JSON response\n        decision_outcome = result.get(\"decision_outcome\", \"\")\n        compensation_awarded = result.get(\"compensation_awarded\", 0.0)\n        completion_status = result.get(\"completion_status\", \"completed\")\n        target_ids = result.get(\"target_ids\", [])\n        if not isinstance(target_ids, list):\n            target_ids = [target_ids]\n\n        # Create and dispatch DecisionMadeEvent\n        events = []\n        for target_id in target_ids:\n            decision_event = DecisionMadeEvent(self.profile_id, target_id, decision_outcome, compensation_awarded, completion_status)\n            events.append(decision_event)\n\n        return events",
          "metadata": {
            "id": 5,
            "name": "make_decision",
            "condition": "null",
            "description": "The Judge makes a final decision on the compensation case, concluding the legal process.",
            "type": "AND",
            "required_variables": [
              {
                "name": "evaluation_status_request",
                "type": "str",
                "context": "agent",
                "description": "Status of the compensation request evaluation process"
              },
              {
                "name": "evaluation_status_defense",
                "type": "str",
                "context": "agent",
                "description": "Status of the defense evaluation process"
              }
            ],
            "output_updates": [
              {
                "name": "decision_outcome",
                "type": "str",
                "context": "env",
                "description": "Outcome of the case decision"
              },
              {
                "name": "compensation_awarded",
                "type": "float",
                "context": "env",
                "description": "Amount of compensation awarded to the plaintiff"
              },
              {
                "name": "completion_status",
                "type": "str",
                "context": "env",
                "description": "Status indicating completion of the case"
              }
            ]
          }
        }
      }
    }
  },
  "events": {
    "imports": "from onesim.events import Event\nfrom typing import Any, List",
    "definitions": {
      "-1": {
        "code": "class StartEvent(Event):\n    def __init__(self,\n        from_agent_id: str,\n        to_agent_id: str,\n        **kwargs: Any\n    ) -> None:\n        super().__init__(from_agent_id=from_agent_id, to_agent_id=to_agent_id, **kwargs)",
        "metadata": {
          "id": -1,
          "from_agent_type": "EnvAgent",
          "from_action_name": "start",
          "to_agent_type": "Plaintiff",
          "to_action_name": "submit_compensation_request",
          "from_action_id": 0,
          "to_action_id": 1,
          "event_name": "StartEvent",
          "event_info": "Initial trigger for Plaintiff to submit compensation request",
          "fields": []
        }
      },
      "-2": {
        "code": "class StartEvent(Event):\n    def __init__(self,\n        from_agent_id: str,\n        to_agent_id: str,\n        **kwargs: Any\n    ) -> None:\n        super().__init__(from_agent_id=from_agent_id, to_agent_id=to_agent_id, **kwargs)",
        "metadata": {
          "id": -2,
          "from_agent_type": "EnvAgent",
          "from_action_name": "start",
          "to_agent_type": "Defendant",
          "to_action_name": "prepare_defense",
          "from_action_id": 0,
          "to_action_id": 2,
          "event_name": "StartEvent",
          "event_info": "Initial trigger for Defendant to prepare defense",
          "fields": []
        }
      },
      "1": {
        "code": "class CompensationRequestEvent(Event):\n    def __init__(self,\n        from_agent_id: str,\n        to_agent_id: str,\n        compensation_amount: float = 0.0,\n        damage_description: str = \"\",\n        evidence_list: List[Any] = [],\n        **kwargs: Any\n    ) -> None:\n        super().__init__(from_agent_id=from_agent_id, to_agent_id=to_agent_id, **kwargs)\n        self.compensation_amount = compensation_amount\n        self.damage_description = damage_description\n        self.evidence_list = evidence_list",
        "metadata": {
          "id": 1,
          "from_agent_type": "Plaintiff",
          "from_action_name": "submit_compensation_request",
          "to_agent_type": "Judge",
          "to_action_name": "evaluate_request",
          "from_action_id": 1,
          "to_action_id": 3,
          "event_name": "CompensationRequestEvent",
          "event_info": "Plaintiff submits compensation request and damage facts",
          "fields": [
            {
              "name": "compensation_amount",
              "type": "float",
              "default_value": "0.0",
              "description": "Requested amount for compensation"
            },
            {
              "name": "damage_description",
              "type": "str",
              "default_value": "",
              "description": "Description of the damages incurred"
            },
            {
              "name": "evidence_list",
              "type": "list",
              "default_value": "[]",
              "description": "List of evidence supporting the compensation request"
            }
          ]
        }
      },
      "2": {
        "code": "class DefensePreparedEvent(Event):\n    def __init__(self,\n        from_agent_id: str,\n        to_agent_id: str,\n        liability_reduction_argument: str = \"\",\n        counter_evidence_list: List[Any] = [],\n        **kwargs: Any\n    ) -> None:\n        super().__init__(from_agent_id=from_agent_id, to_agent_id=to_agent_id, **kwargs)\n        self.liability_reduction_argument = liability_reduction_argument\n        self.counter_evidence_list = counter_evidence_list",
        "metadata": {
          "id": 2,
          "from_agent_type": "Defendant",
          "from_action_name": "prepare_defense",
          "to_agent_type": "Judge",
          "to_action_name": "evaluate_defense",
          "from_action_id": 2,
          "to_action_id": 4,
          "event_name": "DefensePreparedEvent",
          "event_info": "Defendant prepares defense and argues for liability reduction",
          "fields": [
            {
              "name": "liability_reduction_argument",
              "type": "str",
              "default_value": "",
              "description": "Argument prepared by the defendant for reducing liability"
            },
            {
              "name": "counter_evidence_list",
              "type": "list",
              "default_value": "[]",
              "description": "List of evidence countering the plaintiff's claims"
            }
          ]
        }
      },
      "3": {
        "code": "class RequestEvaluationEvent(Event):\n    def __init__(self,\n        from_agent_id: str,\n        to_agent_id: str,\n        evaluation_status: str = 'pending',\n        evaluation_notes: str = \"\",\n        **kwargs: Any\n    ) -> None:\n        super().__init__(from_agent_id=from_agent_id, to_agent_id=to_agent_id, **kwargs)\n        self.evaluation_status = evaluation_status\n        self.evaluation_notes = evaluation_notes",
        "metadata": {
          "id": 3,
          "from_agent_type": "Judge",
          "from_action_name": "evaluate_request",
          "to_agent_type": "Judge",
          "to_action_name": "make_decision",
          "from_action_id": 3,
          "to_action_id": 5,
          "event_name": "RequestEvaluationEvent",
          "event_info": "Judge evaluates the compensation request based on evidence",
          "fields": [
            {
              "name": "evaluation_status",
              "type": "str",
              "default_value": "pending",
              "description": "Status of the evaluation process"
            },
            {
              "name": "evaluation_notes",
              "type": "str",
              "default_value": "",
              "description": "Notes and observations made during the evaluation"
            }
          ]
        }
      },
      "4": {
        "code": "class DefenseEvaluationEvent(Event):\n    def __init__(self,\n        from_agent_id: str,\n        to_agent_id: str,\n        evaluation_status: str = 'pending',\n        evaluation_notes: str = \"\",\n        **kwargs: Any\n    ) -> None:\n        super().__init__(from_agent_id=from_agent_id, to_agent_id=to_agent_id, **kwargs)\n        self.evaluation_status = evaluation_status\n        self.evaluation_notes = evaluation_notes",
        "metadata": {
          "id": 4,
          "from_agent_type": "Judge",
          "from_action_name": "evaluate_defense",
          "to_agent_type": "Judge",
          "to_action_name": "make_decision",
          "from_action_id": 4,
          "to_action_id": 5,
          "event_name": "DefenseEvaluationEvent",
          "event_info": "Judge evaluates the defense arguments based on evidence",
          "fields": [
            {
              "name": "evaluation_status",
              "type": "str",
              "default_value": "pending",
              "description": "Status of the defense evaluation process"
            },
            {
              "name": "evaluation_notes",
              "type": "str",
              "default_value": "",
              "description": "Notes and observations made during the defense evaluation"
            }
          ]
        }
      },
      "5": {
        "code": "class DecisionMadeEvent(Event):\n    def __init__(self,\n        from_agent_id: str,\n        to_agent_id: str,\n        decision_outcome: str = \"\",\n        compensation_awarded: float = 0.0,\n        completion_status: str = 'completed',\n        **kwargs: Any\n    ) -> None:\n        super().__init__(from_agent_id=from_agent_id, to_agent_id=to_agent_id, **kwargs)\n        self.decision_outcome = decision_outcome\n        self.compensation_awarded = compensation_awarded\n        self.completion_status = completion_status",
        "metadata": {
          "id": 5,
          "from_agent_type": "Judge",
          "from_action_name": "make_decision",
          "to_agent_type": "EnvAgent",
          "to_action_name": "terminate",
          "from_action_id": 5,
          "to_action_id": -1,
          "event_name": "DecisionMadeEvent",
          "event_info": "Judge makes a decision on compensation and concludes the case",
          "fields": [
            {
              "name": "decision_outcome",
              "type": "str",
              "default_value": "",
              "description": "Outcome of the case decision"
            },
            {
              "name": "compensation_awarded",
              "type": "float",
              "default_value": "0.0",
              "description": "Amount of compensation awarded to the plaintiff"
            },
            {
              "name": "completion_status",
              "type": "str",
              "default_value": "completed",
              "description": "Status indicating completion of the case"
            }
          ]
        }
      }
    }
  }
}